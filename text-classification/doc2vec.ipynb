{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Doc2Vec\n",
    "The purpose of this section is to apply the word2vec algorithm to our dataset.\n",
    "For now, we'll only use the following columns:\n",
    "[Headline, Industry, College-Name-1,Degree-Name-1,Field-Of-Study-1,Job-Title-1,Company-Name-1,\n",
    "College-Name-2 (Referring to masters), Degree-Name-2 (Referring to masters)]\n",
    "\n",
    "## Important to note\n",
    "We only care about the Headline and Job-Title-1 column since we have some discrepancies in our dataset, as\n",
    "we've described previously sometimes the Headline does not properly reflect the Job-Title-1 Column so for that\n",
    "reason we'll need to apply a bit of logic. For example in for profile_2 column Dates-Employed-1 says 03-2022-Present, this means that the profile_2 is currently employed there but his headline might not reflect that. Thus, we'll apply a bit of logic for this purpose, example: ```if str(employed).find('Present') != -1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Main imports\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from helper import remove_unused_columns, transform_profession, preprocess_text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cleaning up\n",
    "As we mentioned above we'll go ahead and clean up these discrepancies in our dataset.\n",
    "We really only care about the profiles current position."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# reading our files and\n",
    "file = '../excel-data/f-linkedin-profile.csv'\n",
    "data_csv = pd.read_csv(file)\n",
    "data_top = remove_unused_columns(data_csv)[0:13]\n",
    "\n",
    "# Get our columns into lists\n",
    "headline_categories = list(data_csv['Industry'])\n",
    "profession = transform_profession(data_top, data=data_csv)\n",
    "category_list = data_csv['Headline']\n",
    "category_id = [i for i in range(len(category_list))]\n",
    "\n",
    "# Initialize our columns into a dataframe\n",
    "dtf = pd.DataFrame()\n",
    "dtf['category_id'] = category_id\n",
    "dtf['categories'] = headline_categories\n",
    "dtf['profession'] = profession\n",
    "\n",
    "# Clean your data set first remove unwanted words like: \"I\", \"me\", \"you\"\n",
    "list_stop_of_words = stopwords.words('english')\n",
    "dtf['clean_text_profession'] = dtf['profession'].apply(\n",
    "    lambda x: preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=list_stop_of_words))\n",
    "\n",
    "dtf.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "   category_id        categories  \\\n0            0  Machine Learning   \n1            1  Machine Learning   \n2            2  Machine Learning   \n3            3  Machine Learning   \n4            4  Machine Learning   \n\n                                          profession  \\\n0  Director of Data Science, Machine Learning at ...   \n1        Machine learning on Encrypted data Engineer   \n2  Machine Learning Research Scientist - Deep Lea...   \n3             Principal (Manager) R&D Data Scientist   \n4  Vice President of Machine Learning, Merchandis...   \n\n                               clean_text_profession  \n0  director data science machine learning walmart...  \n1           machine learning encrypted data engineer  \n2  machine learning research scientist deep learning  \n3                principal manager rd data scientist  \n4  vice president machine learning merchandising ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_id</th>\n      <th>categories</th>\n      <th>profession</th>\n      <th>clean_text_profession</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Machine Learning</td>\n      <td>Director of Data Science, Machine Learning at ...</td>\n      <td>director data science machine learning walmart...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Machine Learning</td>\n      <td>Machine learning on Encrypted data Engineer</td>\n      <td>machine learning encrypted data engineer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Machine Learning</td>\n      <td>Machine Learning Research Scientist - Deep Lea...</td>\n      <td>machine learning research scientist deep learning</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Machine Learning</td>\n      <td>Principal (Manager) R&amp;D Data Scientist</td>\n      <td>principal manager rd data scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Machine Learning</td>\n      <td>Vice President of Machine Learning, Merchandis...</td>\n      <td>vice president machine learning merchandising ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data set\n",
    "In this section we'll split the data set into training set (70%) test set (30%)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# training set (70%) test set (30%)\n",
    "train, test = train_test_split(dtf, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction - Word Embedding\n",
    "In this section we're introducing google's Word2vec algorithm, but first we'll briefly explain why we're using word embedding. Word embedding is a class of technique where each words are represented by real-valued vectors in a pre-defined vector space.\n",
    "For example every word is mapped to a vector, which are learned in a way to resemble a neural network.\n",
    "Meaning words with a similar context appear in the same corpus. So they will be in the same vector space as we mentioned above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "def read_corpus(categories_text, categories_id):\n",
    "    for i in range(len(categories_text)):\n",
    "        yield TaggedDocument(words=list(categories_text)[i].split(), tags=list(categories_id)[i])\n",
    "\n",
    "\n",
    "train_tagged = list(read_corpus(train.clean_text_profession, train.categories))\n",
    "test_tagged = list(read_corpus(test.clean_text_profession, test.categories))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of words Doc2vec Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 1254371.29it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1373071.39it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 858993.46it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 381029.75it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 762600.73it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1394469.90it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 514244.17it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 653127.63it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1132639.05it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1209168.72it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1409110.01it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 800105.68it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1420293.42it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 488508.56it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1319093.15it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 446276.73it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 319756.35it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1102404.34it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1242756.74it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 784898.99it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1731841.65it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1646843.29it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1376592.08it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 864526.43it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1290555.08it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1443201.38it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 983280.06it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1032444.06it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 858993.46it/s]\n",
      "100%|██████████| 128/128 [00:00<00:00, 1290555.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from sklearn import metrics, linear_model\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model = Doc2Vec(\n",
    "    dm=2,\n",
    "    vector_size=50,\n",
    "    negative=1,\n",
    "    hs=0,\n",
    "    min_count=1,\n",
    "    sample=0,\n",
    "    workers=cores,\n",
    ")\n",
    "\n",
    "model.build_vocab(train_tagged)\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train(utils.shuffle([x for x in tqdm(train_tagged)]), total_examples=len(train_tagged), epochs=3)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs\n",
    "    targets, regressors = zip(*[(doc.tags, model.infer_vector(item for item in doc.words)) for doc in sents])\n",
    "\n",
    "    return targets, regressors\n",
    "\n",
    "y_train, X_train = vec_for_learning(model, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model, test_tagged)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "linear = linear_model.LogisticRegression()\n",
    "linear.fit(X_train, y_train)\n",
    "logistic_prediction = linear.predict(X_test)\n",
    "\n",
    "print('----------- F1 Score ----------')\n",
    "print(metrics.f1_score(y_test, logistic_prediction, average='weighted'))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Accuracy Score -----------')\n",
    "print(metrics.accuracy_score(y_test, logistic_prediction))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Confusion Matrix ----------')\n",
    "print(metrics.confusion_matrix(y_test, logistic_prediction))\n",
    "print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- F1 Score ----------\n",
      "0.015151515151515154\n",
      "\n",
      "\n",
      "----------- Accuracy Score -----------\n",
      "0.09090909090909091\n",
      "\n",
      "\n",
      "----------- Confusion Matrix ----------\n",
      "[[ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0]]\n",
      "\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [Training] LinearSVC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- F1 Score ----------\n",
      "0.015151515151515154\n",
      "\n",
      "\n",
      "----------- Accuracy Score -----------\n",
      "0.09090909090909091\n",
      "\n",
      "\n",
      "----------- Confusion Matrix ----------\n",
      "[[ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0 12  0  0  0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = LinearSVC()\n",
    "LSV = clf.fit(X_train, y_train)\n",
    "\n",
    "linear_svc_prediction = LSV.predict(X_test)\n",
    "\n",
    "print('----------- F1 Score ----------')\n",
    "print(metrics.f1_score(y_test, linear_svc_prediction, average='weighted'))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Accuracy Score -----------')\n",
    "print(metrics.accuracy_score(y_test, linear_svc_prediction))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Confusion Matrix ----------')\n",
    "print(metrics.confusion_matrix(y_test, linear_svc_prediction))\n",
    "print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- F1 Score ----------\n",
      "0.2158667419536985\n",
      "\n",
      "\n",
      "----------- Accuracy Score -----------\n",
      "0.23636363636363636\n",
      "\n",
      "\n",
      "----------- Classification Report ----------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Business       0.67      0.40      0.50         5\n",
      "          Finance       0.00      0.00      0.00        12\n",
      "           Lawyer       1.00      0.40      0.57         5\n",
      " Machine Learning       0.29      0.29      0.29         7\n",
      "        Marketing       0.00      0.00      0.00         1\n",
      "  Product Manager       0.12      1.00      0.22         5\n",
      "        Professor       0.00      0.00      0.00         3\n",
      "            Sales       0.00      0.00      0.00         5\n",
      "Software Engineer       1.00      0.17      0.29        12\n",
      "\n",
      "         accuracy                           0.24        55\n",
      "        macro avg       0.34      0.25      0.21        55\n",
      "     weighted avg       0.42      0.24      0.22        55\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamssissoko/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/williamssissoko/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/williamssissoko/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "SV = clf.fit(X_train, y_train)\n",
    "svc_prediction = SV.predict(X_test)\n",
    "\n",
    "print('----------- F1 Score ----------')\n",
    "print(metrics.f1_score(y_test, svc_prediction, average='weighted'))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Accuracy Score -----------')\n",
    "print(metrics.accuracy_score(y_test, svc_prediction))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Classification Report ----------')\n",
    "print(metrics.classification_report(y_test, svc_prediction))\n",
    "print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Training] Decision Tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- F1 Score ----------\n",
      "0.20646594000801716\n",
      "\n",
      "\n",
      "----------- Accuracy Score -----------\n",
      "0.2\n",
      "\n",
      "\n",
      "----------- Classification Report ----------\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Business       0.27      0.60      0.37         5\n",
      "          Finance       0.14      0.08      0.11        12\n",
      "           Lawyer       0.40      0.40      0.40         5\n",
      " Machine Learning       0.25      0.14      0.18         7\n",
      "        Marketing       0.00      0.00      0.00         1\n",
      "  Product Manager       0.06      0.20      0.09         5\n",
      "        Professor       0.00      0.00      0.00         3\n",
      "            Sales       1.00      0.20      0.33         5\n",
      "Software Engineer       0.40      0.17      0.24        12\n",
      "\n",
      "         accuracy                           0.20        55\n",
      "        macro avg       0.28      0.20      0.19        55\n",
      "     weighted avg       0.31      0.20      0.21        55\n",
      "\n",
      "\n",
      "\n",
      "----------- Confusion Matrix ----------\n",
      "[[3 1 0 0 0 1 0 0 0]\n",
      " [3 1 1 0 3 3 0 0 1]\n",
      " [0 1 2 0 0 2 0 0 0]\n",
      " [1 1 0 1 0 3 0 0 1]\n",
      " [0 0 0 0 0 1 0 0 0]\n",
      " [1 1 1 0 0 1 0 0 1]\n",
      " [0 1 0 1 0 1 0 0 0]\n",
      " [1 0 0 1 1 1 0 1 0]\n",
      " [2 1 1 1 0 4 1 0 2]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(max_depth=20, criterion='gini')\n",
    "\n",
    "DTree = clf.fit(X_train, y_train)\n",
    "dtree_prediction = DTree.predict(X_test)\n",
    "\n",
    "print('----------- F1 Score ----------')\n",
    "print(metrics.f1_score(y_test, dtree_prediction, average='weighted'))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Accuracy Score -----------')\n",
    "print(metrics.accuracy_score(y_test, dtree_prediction))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Classification Report ----------')\n",
    "print(metrics.classification_report(y_test, dtree_prediction))\n",
    "print('\\n')\n",
    "\n",
    "print('----------- Confusion Matrix ----------')\n",
    "print(metrics.confusion_matrix(y_test, dtree_prediction))\n",
    "print('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}