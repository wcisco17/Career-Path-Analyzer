{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Word2Vec\n",
    "The purpose of this section is to apply the word2vec algorithm to our dataset.\n",
    "For now, we'll only use the following columns:\n",
    "[Headline, Industry, College-Name-1,Degree-Name-1,Field-Of-Study-1,Job-Title-1,Company-Name-1,\n",
    "College-Name-2 (Referring to masters), Degree-Name-2 (Referring to masters)]\n",
    "\n",
    "## Important to note\n",
    "We only care about the Headline and Job-Title-1 column since we have some discrepancies in our dataset, as\n",
    "we've described previously sometimes the Headline does not properly reflect the Job-Title-1 Column so for that\n",
    "reason we'll need to apply a bit of logic. For example in for profile_2 column Dates-Employed-1 says 03-2022-Present, this means that the profile_2 is currently employed there but his headline might not reflect that. Thus, we'll apply a bit of logic for this purpose, example: ```if str(employed).find('Present') != -1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import model_selection, manifold, preprocessing as P\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from helper import remove_unused_columns, transform_profession, preprocess_text\n",
    "import gensim\n",
    "from keras import preprocessing, layers, models, Model\n",
    "\n",
    "import seaborn as sns\n",
    "import gensim.downloader as gensim_api\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cleaning up\n",
    "As we mentioned above we'll go ahead and clean up these discrepancies in our dataset.\n",
    "We really only care about the profiles current position."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# reading our files and\n",
    "file = '../excel-data/all-data-linkedin.csv'\n",
    "data_csv = pd.read_csv(file)\n",
    "data_top = remove_unused_columns(data_csv)[0:13]\n",
    "\n",
    "# Get our columns into lists\n",
    "headline_categories = list(data_csv['Industry'])\n",
    "profession = transform_profession(data_top, data=data_csv)\n",
    "category_list = data_csv['Headline']\n",
    "category_id = [i for i in range(len(category_list))]\n",
    "\n",
    "# Initialize our columns into a dataframe\n",
    "dtf = pd.DataFrame()\n",
    "dtf['category_id'] = category_id\n",
    "dtf['categories'] = headline_categories\n",
    "dtf['profession'] = profession\n",
    "\n",
    "# Clean your data set first remove unwanted words like: \"I\", \"me\", \"you\"\n",
    "list_stop_of_words = stopwords.words('english')\n",
    "dtf['clean_text_profession'] = dtf['profession'].apply(lambda x: preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=list_stop_of_words))\n",
    "\n",
    "dtf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 621,
   "outputs": [
    {
     "data": {
      "text/plain": "   category_id        categories  \\\n0            0  Machine Learning   \n1            1  Machine Learning   \n2            2  Machine Learning   \n3            3  Machine Learning   \n4            4  Machine Learning   \n\n                                          profession  \\\n0  Director of Data Science, Machine Learning at ...   \n1        Machine learning on Encrypted data Engineer   \n2  Machine Learning Research Scientist - Deep Lea...   \n3             Principal (Manager) R&D Data Scientist   \n4  Vice President of Machine Learning, Merchandis...   \n\n                               clean_text_profession  \n0  director data science machine learning walmart...  \n1           machine learning encrypted data engineer  \n2  machine learning research scientist deep learning  \n3                principal manager rd data scientist  \n4  vice president machine learning merchandising ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category_id</th>\n      <th>categories</th>\n      <th>profession</th>\n      <th>clean_text_profession</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Machine Learning</td>\n      <td>Director of Data Science, Machine Learning at ...</td>\n      <td>director data science machine learning walmart...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Machine Learning</td>\n      <td>Machine learning on Encrypted data Engineer</td>\n      <td>machine learning encrypted data engineer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Machine Learning</td>\n      <td>Machine Learning Research Scientist - Deep Lea...</td>\n      <td>machine learning research scientist deep learning</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Machine Learning</td>\n      <td>Principal (Manager) R&amp;D Data Scientist</td>\n      <td>principal manager rd data scientist</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Machine Learning</td>\n      <td>Vice President of Machine Learning, Merchandis...</td>\n      <td>vice president machine learning merchandising ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split data set\n",
    "In this section we'll split the data set into training set (70%) test set (30%)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "outputs": [],
   "source": [
    "# training set (70%) test set (30%)\n",
    "X_train, Y_test, y_train, y_test = train_test_split(dtf['clean_text_profession'], dtf['categories'], random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction - Word Embedding\n",
    "In this section we're introducing google's Word2vec algorithm, but first we'll briefly explain why we're using word embedding. Word embedding is a class of technique where each words are represented by real-valued vectors in a pre-defined vector space.\n",
    "For example every word is mapped to a vector, which are learned in a way to resemble a neural network.\n",
    "Meaning words with a similar context appear in the same corpus. So they will be in the same vector space as we mentioned above."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word2Vec\n",
    "How does Word2vec tie into this? Well word2vec produces a vector space (with several hundred of dimensions). Each unique word in the corpus share a common context in the corpus as the close to the other in the space.\n",
    "\n",
    "In this section we'll use our own data corpus which we created above when we removed words from our data-set. Words like I, me, you ect.\n",
    "\n",
    "### Skip-gram model\n",
    "***Predicts words within a certain range before and after the current word in the same sentences.***\n",
    "Before fitting the model we'll transform our list into a lists of n-grams. As per the original paper, we'll apply this formula to find the nearby words: vec('Madrid') - vec('Spain') + vec('France') will lead us closer to vec('Paris') than any other vector."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('life', 0.3165738880634308)\n",
      "('marketing', 0.2569739520549774)\n",
      "('startup', 0.24796059727668762)\n",
      "('northwestern', 0.2437247335910797)\n",
      "('contract', 0.23932676017284393)\n",
      "('director', 0.21964438259601593)\n",
      "('international', 0.21706047654151917)\n",
      "('chief', 0.21428938210010529)\n",
      "('fellow', 0.18916472792625427)\n",
      "('creative', 0.1853596717119217)\n"
     ]
    }
   ],
   "source": [
    "corpus = dtf['clean_text_profession']\n",
    "\n",
    "lst_corpus = []\n",
    "for string in corpus:\n",
    "   lst_words = string.split()\n",
    "   lst_grams = [\" \".join(lst_words[i:i+1])\n",
    "               for i in range(0, len(lst_words), 1)]\n",
    "   lst_corpus.append(lst_grams)\n",
    "\n",
    "\n",
    "## detect bigrams and trigrams\n",
    "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus)\n",
    "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
    "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], min_count=5, threshold=10)\n",
    "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)\n",
    "\n",
    "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, min_count=1,vector_size=100, sg=1)\n",
    "\n",
    "nlp.build_vocab(lst_corpus, progress_per=10000)\n",
    "nlp.train(lst_corpus, total_examples=nlp.corpus_count, epochs=1, report_delay=1)\n",
    "\n",
    "word = \"engineer\"\n",
    "\n",
    "## word embedding\n",
    "tot_words = [word] + [tupla[0] for tupla in nlp.wv.most_similar(word, topn=10)]\n",
    "\n",
    "X = nlp.wv[tot_words]\n",
    "\n",
    "for item in nlp.wv.most_similar(word, topn=10):\n",
    "    print(item)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}